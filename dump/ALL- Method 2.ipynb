{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8b210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf8e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files=[]\n",
    "paths = []\n",
    "for dirname, _, filenames in os.walk('../input/leukemia/Original/Pro'):\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename)    \n",
    "        paths.append(path)\n",
    "        files.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d548a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpaths = []\n",
    "for dirname, _, filenames in os.walk('../input/leukemia/Segmented/Pro'):\n",
    "    for filename in filenames:\n",
    "        path = os.path.join(dirname, filename)    \n",
    "        mpaths.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4aedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df0=pd.DataFrame(columns=['file','path','mpath'])\n",
    "df0['file']=sorted(files)\n",
    "df0['path']=sorted(paths)\n",
    "df0['mpath']=sorted(mpaths)\n",
    "display(df0)\n",
    "df=df0.iloc[0:len(df0)//2]\n",
    "test_df=df0.iloc[len(df0)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a32821",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = [256,256]\n",
    "\n",
    "def data_augmentation(car_img, mask_img):\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        car_img = tf.image.flip_left_right(car_img)\n",
    "        mask_img = tf.image.flip_left_right(mask_img)\n",
    "\n",
    "    return car_img, mask_img\n",
    "\n",
    "def preprocessing(car_path, mask_path):\n",
    "    car_img = tf.io.read_file(car_path) \n",
    "    car_img = tf.image.decode_jpeg(car_img, channels=3)\n",
    "    car_img = tf.image.resize(car_img, img_size)\n",
    "    car_img = tf.cast(car_img, tf.float32) / 255.0\n",
    "    \n",
    "    mask_img = tf.io.read_file(mask_path)\n",
    "    mask_img = tf.image.decode_jpeg(mask_img, channels=3)\n",
    "    mask_img = tf.image.resize(mask_img, img_size)\n",
    "    mask_img = mask_img[:,:,:1]    \n",
    "    mask_img = tf.math.sign(mask_img)\n",
    "    \n",
    "    return car_img, mask_img\n",
    "\n",
    "def create_dataset(df, train = False):\n",
    "    if not train:\n",
    "        ds = tf.data.Dataset.from_tensor_slices((df[\"path\"].values, df[\"mpath\"].values))\n",
    "        ds = ds.map(preprocessing, tf.data.AUTOTUNE)\n",
    "    else:\n",
    "        ds = tf.data.Dataset.from_tensor_slices((df[\"path\"].values, df[\"mpath\"].values))\n",
    "        ds = ds.map(preprocessing, tf.data.AUTOTUNE)\n",
    "        ds = ds.map(data_augmentation, tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e65fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = train_test_split(df, random_state=42, test_size=.25)\n",
    "train = create_dataset(train_df, train = True)\n",
    "valid = create_dataset(valid_df)\n",
    "test = create_dataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7bfc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = len(train_df)\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8352c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "valid_dataset = valid.batch(BATCH_SIZE)\n",
    "test_dataset = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5acb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(12,12))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be3dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    for image, mask in train.take(i):\n",
    "        sample_image, sample_mask = image, mask\n",
    "        display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3e4a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=[256, 256, 3], include_top=False)\n",
    "\n",
    "# Use the activations of these layers\n",
    "layer_names = [\n",
    "    'block_1_expand_relu',   # 64x64\n",
    "    'block_3_expand_relu',   # 32x32\n",
    "    'block_6_expand_relu',   # 16x16\n",
    "    'block_13_expand_relu',  # 8x8\n",
    "    'block_16_project',      # 4x4\n",
    "]\n",
    "base_model_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "down_stack = tf.keras.Model(inputs=base_model.input, outputs=base_model_outputs)\n",
    "down_stack.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, norm_type='batchnorm', apply_dropout=False):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    \n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(\n",
    "      tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\n",
    "                                      padding='same',\n",
    "                                      kernel_initializer=initializer,\n",
    "                                      use_bias=False))\n",
    "\n",
    "    if norm_type.lower() == 'batchnorm':\n",
    "        result.add(tf.keras.layers.BatchNormalization())\n",
    "    elif norm_type.lower() == 'instancenorm':\n",
    "        result.add(InstanceNormalization())\n",
    "\n",
    "    if apply_dropout:\n",
    "        result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "        result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "    return result\n",
    "\n",
    "up_stack = [\n",
    "    upsample(512, 3),  # 4x4 -> 8x8\n",
    "    upsample(256, 3),  # 8x8 -> 16x16\n",
    "    upsample(128, 3),  # 16x16 -> 32x32\n",
    "    upsample(64, 3),   # 32x32 -> 64x64\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380cb69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(output_channels):\n",
    "    inputs = tf.keras.layers.Input(shape=[256, 256, 3])\n",
    "\n",
    "    # Downsampling through the model\n",
    "    skips = down_stack(inputs)\n",
    "    x = skips[-1]\n",
    "    skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        concat = tf.keras.layers.Concatenate()\n",
    "        x = concat([x, skip])\n",
    "\n",
    "  # This is the last layer of the model\n",
    "    last = tf.keras.layers.Conv2DTranspose(\n",
    "      output_channels, 3, strides=2, activation='sigmoid',\n",
    "      padding='same')  #64x64 -> 128x128\n",
    "\n",
    "    x = last(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d491586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "\n",
    "def dice_loss(in_gt, in_pred):\n",
    "    return 1-dice_coef(in_gt, in_pred)\n",
    "\n",
    "model = unet_model(1)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss = dice_loss,\n",
    "              metrics=[dice_coef,'binary_accuracy'])\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(display_list):\n",
    "    plt.figure(figsize=(12,12))\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_predictions(sample_image, sample_mask):\n",
    "    pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
    "    pred_mask = pred_mask.reshape(img_size[0],img_size[1],1)\n",
    "    visualize([sample_image, sample_mask, pred_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a296e763",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    for images, masks in train_dataset.take(i):\n",
    "        for img, mask in zip(images, masks):\n",
    "            sample_image = img\n",
    "            sample_mask = mask\n",
    "            show_predictions(sample_image, sample_mask)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6217742",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(patience=4,restore_best_weights=True)\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if (epoch + 1) % 3 == 0:\n",
    "            show_predictions(sample_image, sample_mask)\n",
    "EPOCHS = 30\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "\n",
    "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_data=valid_dataset,\n",
    "                          callbacks=[DisplayCallback(), early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    for images, masks in test_dataset.take(i):\n",
    "        for img, mask in zip(images, masks):\n",
    "            tsample_image = img\n",
    "            tsample_mask = mask\n",
    "            show_predictions(tsample_image, tsample_mask)\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
